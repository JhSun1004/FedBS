## FedAvg
简单聚合，根据数据量大小对子模型参数**加权和**得到全局模型。
## FedProx
- 允许每个设备根据其系统资源执行**不同数量的本地迭代**。这意味着，与FedAvg不同，FedProx不会丢弃那些无法完成指定迭代次数的设备（被称为落后者）。相反，它会将这些设备的部分更新纳入全局模型中。 

- 为了进一步稳定方法并限制来自不同设备的局部更新的影响，FedProx在每个设备的本地目标函数中添加了一个**近端项**。这个近端项有助于确保更新不会偏离全局模型太远，从而在存在统计异质性的情况下提高了算法的稳定性。

算法流程：
1. 选择一部分设备进行本地更新。
2. 每个被选中的设备执行一定数量的本地SGD迭代，以达到γ-inexact解（即，局部梯度与全局梯度的范数之比小于γ）。
3. 将每个设备的局部更新发送回中央服务器。
4. 中央服务器使用近端项来计算全局更新，并更新全局模型。
## Per-FedAvg
利用所有客户端的数据得到一个初始模型，然后各个客户端使用该初始模型在本地进行几次**梯度下降**就能得到最终模型。
## FedPer
所有客户端模型共享基本层，然后由于数据分布的不同，不同客户端模型具有不同的**个性化顶层**。只上传基本层。
## PFedMe
利用了Moreau envelope函数，将个性化模型优化从全局模型学习中分解出来，使得 pFedMe在类似于 FedAvg 更新全局模型的同时，根据T时刻每个客户端的本地数据分布并行优化个性化模型。
## FedRep
利用客户端之间数据的共同特征表示来提升个性化模型的学习。这种方法假设尽管不同客户端的数据分布可能存在差异，但他们可能共享一个全局的特征空间，而每个客户端的特定信息则通过本地头来捕捉。

步骤：
1. 客户端更新
   - 在每一轮中，一部分客户端被选中进行更新。
   - 选中的客户端根据当前的全局表示（global representation）和本地数据，执行多次本地梯度下降（或其他优化算法）来更新其本地头（local head）。
   - 每个客户端的目标是找到最优的**本地头**，使得在给定全局表示的情况下，本地损失最小。
2. 服务器更新
   - 客户端完成本地头的更新后，将更新的全局表示发送回服务器。
   - 服务器收集所有客户端的更新，并通过某种聚合机制（如平均）来更新全局表示。
## Ditto
Ditto框架通过在每个客户端上学习一个个性化模型来解决这些问题。这种方法可以看作是传统全局联邦学习的一个轻量级个性化附加组件。Ditto适用于凸和非凸目标，并继承了传统联邦学习的类似隐私和效率属性。

步骤：
1. 服务器随机选择一部分客户端，并将当前的全局模型发送给它们。
2. 每个被选中的客户端使用本地数据来更新其个性化模型，并计算全局模型的更新。
3. 服务器聚合所有客户端的全局模型更新来更新全局模型。

Ditto和ALA有相似之处，都相当于一个附加组件，区别在于ALA将前一次迭代的本地模型与全局模型加权和得到新的本地模型，而Ditto使用本地数据更新个性化模型，并计算全局模型的更新。

## LG-FedAvg
学习多个局部表示和单个全局头
减少上传参数量
公平表征

## FedBABU
FedBABU算法的核心思想是将模型分为两部分：身体（body）和头部（head）。身体负责特征提取，与模型的泛化能力相关；头部负责分类决策，与个性化相关。

- 初始化：全局模型参数被初始化，包括身体参数θext和头部参数θcls。
- 客户端采样：选择一组客户端参与每轮训练。
- 广播：服务器将全局模型参数广播给选中的客户端。
- 本地更新：每个客户端使用本地数据对广播的模型进行训练，但只更新模型的身体部分。头部参数θcls在这一阶段保持不变。
- 聚合：在聚合阶段，服务器只聚合各客户端更新后的身体参数，而不会聚合头部参数。
- 个性化微调：在联邦训练完成后，每个客户端可以使用自己的数据对全局模型的头部进行微调，以实现个性化。

## FedTHE+

## FedPAC